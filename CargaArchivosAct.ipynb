{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "localidad = pd.read_csv(\"../Datasets/Localidades.csv\",delimiter = ',',encoding = \"utf-8\")\n",
    "cliente = pd.read_csv(\"../Datasets/Clientes.csv\",encoding = \"utf-8\",delimiter = ';', usecols=[\"ID\",\"Provincia\",\"Nombre_y_Apellido\",\"Domicilio\",\"Telefono\",\"Edad\",\"Localidad\",\"X\",\"Y\",\"col10\"])\n",
    "proveedor = pd.read_csv(\"../Datasets/Proveedores.csv\",delimiter = ',',encoding = \"ansi\")\n",
    "gasto = pd.read_csv(\"../Datasets/Gasto.csv\",delimiter = ',',encoding = \"utf-8\")\n",
    "compra = pd.read_csv(\"../Datasets/Compra.csv\",delimiter = ',',encoding = \"utf-8\")\n",
    "sucursal = pd.read_csv(\"../Datasets/Sucursales.csv\",delimiter = ';',encoding = \"utf-8\")\n",
    "venta = pd.read_csv('../Datasets/Venta.csv', delimiter= ',', encoding= \"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo dataframe\n",
    "provincias = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLA VENTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CargaArchivoVenta():\n",
    "    #ds_path= pathlib.Path(\"Datasets\")\n",
    "    #print(ds_path)\n",
    "    df_list=[]\n",
    "    #archivo=glob.glob('.csv')\n",
    "    #print(\"Hola\")\n",
    "    for file in glob.glob('Vent*.csv'):\n",
    "        #print(file)\n",
    "        df=pd.read_csv(file,delimiter = ',',encoding = \"utf-8\")\n",
    "        df_list.append(df)\n",
    "    venta=pd.concat(df_list)\n",
    "    #Tratamiento outliers columna precio\n",
    "    #Precio maximo de venta\n",
    "    #venta['Precio'].max()\n",
    "\n",
    "    Q1 = venta[\"Precio\"].quantile(0.25)\n",
    "    Q3 = venta[\"Precio\"].quantile(0.75)\n",
    "    #Se calcula el rango intercuartilico IQR.\n",
    "    IQR = Q3 -Q1\n",
    "\n",
    "    #Uso de mascara para filtrar\n",
    "    outliersSup = (Q3 + (1.5*IQR))\n",
    "\n",
    "    #Uso la mascara para filtrar\n",
    "    mask = venta[\"Precio\"]<outliersSup\n",
    "    VentaSinOut2 = venta[mask]\n",
    "    #VentaSinOut2.describe().T\n",
    "\n",
    "    #Compruebo cantidad de outliers\n",
    "    #venta.shape[0]-VentaSinOut2.shape[0]\n",
    "\n",
    "    #Tratamiento de outliers\n",
    "    Precio_Producto= VentaSinOut2.groupby([\"IdProducto\"])[\"Precio\"].mean().reset_index()\n",
    "    Precio_Producto= Precio_Producto.rename(columns= {\"Precio\":\"Precio2\"})\n",
    "    venta = pd.merge(venta,Precio_Producto, how=\"left\", on=[\"IdProducto\"])\n",
    "    venta.sort_values(\"IdVenta\")\n",
    "\n",
    "    #Se reemplazan los 0 de precios2 por el valor de la media de los precios sin outlier\n",
    "    venta.Precio2.fillna(VentaSinOut2.Precio.mean(), inplace=True) #1065\n",
    "\n",
    "    #venta.isnull().sum()\n",
    "\n",
    "    #Se reemplazan con 0 y 1 todos los valores de precios vacios y cantidades\n",
    "    venta.Precio.fillna(0, inplace= True)\n",
    "    venta.Cantidad.fillna(1, inplace= True)\n",
    "\n",
    "    #se crea columna con unos\n",
    "    venta['Outliers'] = np.ones(venta.shape[0])\n",
    "\n",
    "    #Se marcan con 0 las filas que son outliers para reemplazarlas con precios 2 despues\n",
    "    venta.loc[(venta['Precio']>=outliersSup),'Outliers'] = 0\n",
    "\n",
    "    #Este for reemplaza los 0 y los outliers por el precio promedio sin outliers\n",
    "    for i in range(0,venta.shape[0]):\n",
    "        if venta.Precio[i] == 0 or venta.Precio[i]> outliersSup:\n",
    "            venta.Precio[i] = venta.Precio2[i]\n",
    "\n",
    "    venta.drop(columns=['Precio2'], inplace=True)\n",
    "    #venta['Total_venta'] = venta['Precio']*venta['Cantidad']\n",
    "\n",
    "    #venta.isnull().sum()\n",
    "\n",
    "    #tratamiento outliers columna cantidad\n",
    "    Q1 = venta[\"Cantidad\"].quantile(0.25)\n",
    "    Q3 = venta[\"Cantidad\"].quantile(0.75)\n",
    "\n",
    "    #se calcula el rango intercuartilico IQR.\n",
    "    IQR = Q3 -Q1\n",
    "    outliersSup = (Q3 + (1.5*IQR)) \n",
    "    mask = venta[\"Cantidad\"]<outliersSup\n",
    "    ventaCantSinOut = venta[mask]\n",
    "    cantidadMedia = round(ventaCantSinOut.Cantidad.mean())\n",
    "    venta.loc[(venta['Cantidad'] >= outliersSup),\"Cantidad\"] = cantidadMedia #2\n",
    "\n",
    "    #se crea la columna Total\n",
    "    venta[\"Ventas_Totales\"]= venta[\"Precio\"]*venta[\"Cantidad\"]\n",
    "\n",
    " \n",
    "    venta.to_csv(r'C:/Users/notebook/OneDrive/Escritorio/Henry clase/DS-PI-ProyectoIndividual/Nuevosdataset/VentasNor.csv', index =False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\notebook\\AppData\\Local\\Temp\\ipykernel_6672\\2595160031.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  venta.Precio[i] = venta.Precio2[i]\n"
     ]
    }
   ],
   "source": [
    "CargaArchivoVenta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLA COMPRAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CargaArchivoCompra():\n",
    "    #ds_path= pathlib.Path(\"Datasets\")\n",
    "    #print(ds_path)\n",
    "    df_list=[]\n",
    "    #archivo=glob.glob('.csv')\n",
    "    #print(\"Hola\")\n",
    "    for file in glob.glob('Compr*.csv'):\n",
    "        print(file)\n",
    "        df=pd.read_csv(file,delimiter = ',',encoding = \"utf-8\")\n",
    "        df_list.append(df)\n",
    "    compra=pd.concat(df_list)\n",
    "    #compra.head()\n",
    "    #tratamiento outliers precio\n",
    "    #Precio maximo de compra\n",
    "    #compra['Precio'].max()\n",
    "\n",
    "    Q1 = compra[\"Precio\"].quantile(0.25)\n",
    "    Q3 = compra[\"Precio\"].quantile(0.75)\n",
    "    #Se calcula el rango intercuartilico IQR.\n",
    "    IQR = Q3 -Q1\n",
    "    outliersSup = (Q3 + (1.5*IQR))\n",
    "\n",
    "    #Uso de mascara para filtrar\n",
    "    mask = compra[\"Precio\"]<outliersSup\n",
    "    CompraSinOut2 = compra[mask]\n",
    "    #CompraSinOut2.describe().T\n",
    "\n",
    "    #Compruebo cantidad de outliers\n",
    "    #compra.shape[0]-CompraSinOut2.shape[0]\n",
    "\n",
    "    #Tratamiento de outliers\n",
    "    Precio_Producto= CompraSinOut2.groupby([\"IdProducto\"])[\"Precio\"].mean().reset_index()\n",
    "    Precio_Producto= Precio_Producto.rename(columns= {\"Precio\":\"Precio2\"})\n",
    "    compra = pd.merge(compra,Precio_Producto, how=\"left\", on=[\"IdProducto\"])\n",
    "    compra.sort_values(\"IdCompra\")\n",
    "\n",
    "    #Se reemplazan los 0 de precios2 por el valor de la media de los precios sin outliers\n",
    "    compra.Precio2.fillna(CompraSinOut2.Precio.mean(),inplace = True)\n",
    "\n",
    "    #compra.isnull().sum\n",
    "\n",
    "    #Se reemplazan con 0 y 1 todos los valores de precios vacios y cantidades\n",
    "    compra.Precio.fillna(0, inplace= True)\n",
    "    compra.Cantidad.fillna(1, inplace= True)\n",
    "\n",
    "    #se crea columna con unos\n",
    "    compra['Outliers'] = np.ones(compra.shape[0])\n",
    "\n",
    "    #Se marcan con 0 las filas que son outliers para reemplazarlas con precios 2 despues\n",
    "    compra.loc[(compra['Precio']>=outliersSup),'Outliers'] = 0\n",
    "\n",
    "    #Este for reemplaza los 0 y los outliers por el precio promedio sin outliers\n",
    "    for i in range(0,compra.shape[0]):\n",
    "        if compra.Precio[i] == 0 or compra.Precio[i]> outliersSup:\n",
    "            compra.Precio[i] = compra.Precio2[i] #PRECIO2 ES EL PRECIO PROMEDIO SIN OUTLIERS\n",
    "\n",
    "\n",
    "    compra.drop(columns=['Precio2'], inplace=True)\n",
    "    #compra['Total venta'] = compra['Precio']*compra['Cantidad']\n",
    "\n",
    "    #compra.isnull().sum()\n",
    "\n",
    "    #tratamiento outliers cantidad\n",
    "    #Se calcula el rango intercuartilico IQR.\n",
    "    Q1 = compra[\"Cantidad\"].quantile(0.25)\n",
    "    Q3 = compra[\"Cantidad\"].quantile(0.75)\n",
    "    IQR = Q3 -Q1\n",
    "    outliersSup = (Q3 + (1.5*IQR)) \n",
    "\n",
    "    # se crea un df sin outliers, se calcula la media de compras,y se imputan como valor en los casos que sean outliers.\n",
    "    mask = compra[\"Cantidad\"]<outliersSup\n",
    "    compraCantSinOut = compra[mask]\n",
    "    cantidadMedia = round(compraCantSinOut.Cantidad.mean())\n",
    "    compra.loc[(compra['Cantidad'] >= outliersSup),\"Cantidad\"] = cantidadMedia #8\n",
    "    compra[\"Compras_Totales\"]= compra[\"Precio\"]*compra[\"Cantidad\"]\n",
    "    compra.to_csv (r'C:/Users/notebook/OneDrive/Escritorio/Henry clase/DS-PI-ProyectoIndividual/Nuevosdataset/ComprasNor.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compra.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\notebook\\AppData\\Local\\Temp\\ipykernel_6672\\3997040176.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  compra.Precio[i] = compra.Precio2[i] #PRECIO2 ES EL PRECIO PROMEDIO SIN OUTLIERS\n"
     ]
    }
   ],
   "source": [
    "CargaArchivoCompra()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLA LOCALIDADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CargaArchivoLocalidades():\n",
    "    #ds_path= pathlib.Path(\"Datasets\")\n",
    "    #print(ds_path)\n",
    "    df_list=[]\n",
    "    #archivo=glob.glob('.csv')\n",
    "    #print(\"Hola\")\n",
    "    for file in glob.glob('Localida*.csv'):\n",
    "        #print(file)\n",
    "        df=pd.read_csv(file,delimiter = ',',encoding = \"utf-8\")\n",
    "        df_list.append(df)\n",
    "    global localidad\n",
    "    localidad=pd.concat(df_list)\n",
    "    #Tabla localidad\n",
    "    #localidad.head()\n",
    "    #localidad.isna().sum()\n",
    "\n",
    "    #acomodo nombres\n",
    "    localidad['nombre']=localidad.apply(lambda x: 'Ciudad de Buenos Aires' if x['municipio_nombre']=='Capital Federal' else x['nombre'], axis=1)\n",
    "\n",
    "    #localidad.isna().sum()\n",
    "\n",
    "    #corrijo nulos\n",
    "    localidad[\"departamento_id\"].fillna(\"Sin datos\", inplace=True)\n",
    "    localidad[\"departamento_nombre\"].fillna(\"Sin datos\", inplace=True)\n",
    "\n",
    "    #Corrijo letras\n",
    "    localidad[\"provincia_nombre\"]=[x.replace('á',\"a\") for x in localidad[\"provincia_nombre\"]]\n",
    "    localidad[\"provincia_nombre\"]=[x.replace('é',\"e\") for x in localidad[\"provincia_nombre\"]]\n",
    "    localidad[\"provincia_nombre\"]=[x.replace('í',\"i\") for x in localidad[\"provincia_nombre\"]]\n",
    "    localidad[\"provincia_nombre\"]=[x.replace('ó',\"o\") for x in localidad[\"provincia_nombre\"]]\n",
    "    localidad[\"provincia_nombre\"]=[x.replace('ú',\"u\") for x in localidad[\"provincia_nombre\"]]\n",
    "\n",
    "    localidad[\"nombre\"]=[x.replace('á',\"a\") for x in localidad[\"nombre\"]]\n",
    "    localidad[\"nombre\"]=[x.replace('é',\"e\") for x in localidad[\"nombre\"]]\n",
    "    localidad[\"nombre\"]=[x.replace('í',\"i\") for x in localidad[\"nombre\"]]\n",
    "    localidad[\"nombre\"]=[x.replace('ó',\"o\") for x in localidad[\"nombre\"]]\n",
    "    localidad[\"nombre\"]=[x.replace('ú',\"u\") for x in localidad[\"nombre\"]]\n",
    "\n",
    "    #Renombro columnas que tienen valores de Latitud y Longitud\n",
    "    localidad= localidad.rename(columns= {\"centroide_lat\":\"Latitud\"})\n",
    "    localidad= localidad.rename(columns= {\"centroide_lon\":\"Longitud\"})\n",
    "\n",
    "    #Creo dataframe de provincia\n",
    "    provincias['Provincia'] = localidad.provincia_nombre\n",
    "    provincias['IdProvincia'] = localidad.provincia_id\n",
    "\n",
    "    #Borro duplicados\n",
    "    provincias.drop_duplicates(inplace=True)\n",
    "\n",
    "    #Renombro columnas\n",
    "    localidad= localidad.rename(columns= {\"provincia_nombre\":\"Provincia\"})\n",
    "\n",
    "    #Borro columnas\n",
    "    localidad.drop(columns='departamento_nombre',inplace=True)\n",
    "\n",
    "    #Capitalizo columna nombre\n",
    "    localidad[\"nombre\"]= localidad[\"nombre\"].str.title()\n",
    "\n",
    "    #Cambio nombre de las columnas\n",
    "    localidad= localidad.rename(columns= {\"id\":\"IdLocalidad\", \"nombre\":\"Localidad\",\"provincia_id\":\"IdProvincia\", \"departamento_id\":\"IdDepartamento\"})\n",
    "\n",
    "    #Borroduplicados\n",
    "    localidad.drop_duplicates(subset=[\"Localidad\",\"IdProvincia\"], inplace=True)\n",
    "    localidad.reset_index(inplace=True)\n",
    "\n",
    "    #Borro columnas\n",
    "    localidad.drop(['categoria','fuente', 'localidad_censal_id', 'localidad_censal_nombre', 'municipio_id', 'municipio_nombre', 'IdDepartamento'], axis = 'columns', inplace=True)\n",
    "\n",
    "    #Creo nueva fila nula\n",
    "    localidad=localidad.append({'Latitud' : 0 , 'Longitud' : 0, 'IdLocalidad' : 0, 'Localidad':\"Sin Datos\",\"Provincia\":\"Sin Datos\"} , ignore_index=True)\n",
    "    \n",
    "    localidad.to_csv (r'C:/Users/notebook/OneDrive/Escritorio/Henry clase/DS-PI-ProyectoIndividual/Nuevosdataset/LocalidadesNor.csv', index = False, header=True)\n",
    "    provincias.to_csv (r'C:/Users/notebook/OneDrive/Escritorio/Henry clase/DS-PI-ProyectoIndividual/Nuevosdataset/ProvinciasNor.csv', index = False, header=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\notebook\\AppData\\Local\\Temp\\ipykernel_6672\\4288571138.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  localidad=localidad.append({'Latitud' : 0 , 'Longitud' : 0, 'IdLocalidad' : 0, 'Localidad':\"Sin Datos\",\"Provincia\":\"Sin Datos\"} , ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "CargaArchivoLocalidades()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLA CLIENTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CargaArchivoClientes():\n",
    "    #ds_path= pathlib.Path(\"Datasets\")\n",
    "    #print(ds_path)\n",
    "    df_list=[]\n",
    "    #archivo=glob.glob('.csv')\n",
    "    #print(\"Hola\")\n",
    "    for file in glob.glob('Client*.csv'):\n",
    "        #print(file)\n",
    "        df=pd.read_csv(file,delimiter = ';',encoding = \"utf-8\", usecols=[\"ID\",\"Provincia\",\"Nombre_y_Apellido\",\"Domicilio\",\"Telefono\",\"Edad\",\"Localidad\",\"X\",\"Y\",\"col10\"])\n",
    "        df_list.append(df)\n",
    "    cliente=pd.concat(df_list)\n",
    "    #cliente.head()\n",
    "    #cliente.info()\n",
    "    #cliente.shape\n",
    "    #cliente.isnull().sum()\n",
    "\n",
    "    #Drop col10 que tiene todos los valores vacios\n",
    "    cliente.drop(columns= 'col10', inplace = True)\n",
    "\n",
    "    #corrijo nombres\n",
    "    cliente= cliente.rename(columns= {\"ID\":\"IdCliente\"})\n",
    "    cliente= cliente.rename(columns= {\"X\":\"Longitud\"})\n",
    "    cliente= cliente.rename(columns= {\"Y\":\"Latitud\"})\n",
    "\n",
    "    #corrijo mayuscula\n",
    "    cliente[\"Nombre_y_Apellido\"]= cliente[\"Nombre_y_Apellido\"].str.title()\n",
    "    cliente[\"Domicilio\"]= cliente[\"Domicilio\"].str.title()\n",
    "    cliente[\"Localidad\"]= cliente[\"Localidad\"].str.title()\n",
    "\n",
    "    #reemplazo faltantes\n",
    "    cliente.Provincia.fillna(\"Sin Datos\", inplace=True)\n",
    "    cliente.Nombre_y_Apellido.fillna(\"Sin Datos\", inplace=True)\n",
    "    cliente.Localidad.fillna(\"Sin Datos\", inplace=True)\n",
    "    cliente.Telefono.fillna(\"Sin Datos\", inplace=True)\n",
    "    cliente.Domicilio.fillna(\"Sin Datos\", inplace=True)\n",
    "\n",
    "    #cliente.isnull().sum()\n",
    "\n",
    "    #reemplazo coma por punto\n",
    "    cliente[\"Longitud\"] = cliente[\"Longitud\"].str.replace(\",\", \".\")\n",
    "    cliente[\"Latitud\"] = cliente[\"Latitud\"].str.replace(\",\", \".\")\n",
    "\n",
    "    #reemplazo Latitud y Longitud que son nulos con ceros\n",
    "    cliente.Latitud.fillna(0.0, inplace=True)\n",
    "    cliente.Longitud.fillna(0.0, inplace=True)\n",
    "\n",
    "    #normalizo provincia de Buenos Aires\n",
    "    cliente[\"Provincia\"]=cliente.apply(lambda x: \"Buenos Aires\" if x[\"Provincia\"]==\"Ciudad de Buenos Aires\"  else x[\"Provincia\"], axis=1)\n",
    "\n",
    "    #acomodo acentos\n",
    "    cliente[\"Provincia\"]=[x.replace('á',\"a\") for x in cliente[\"Provincia\"]]\n",
    "    cliente[\"Provincia\"]=[x.replace('é',\"e\") for x in cliente[\"Provincia\"]]\n",
    "    cliente[\"Provincia\"]=[x.replace('í',\"i\") for x in cliente[\"Provincia\"]]\n",
    "    cliente[\"Provincia\"]=[x.replace('ó',\"o\") for x in cliente[\"Provincia\"]]\n",
    "    cliente[\"Provincia\"]=[x.replace('ú',\"u\") for x in cliente[\"Provincia\"]]\n",
    "    cliente[\"Localidad\"]=[x.replace('á',\"a\") for x in cliente[\"Localidad\"]]\n",
    "    cliente[\"Localidad\"]=[x.replace('é',\"e\") for x in cliente[\"Localidad\"]]\n",
    "    cliente[\"Localidad\"]=[x.replace('í',\"i\") for x in cliente[\"Localidad\"]]\n",
    "    cliente[\"Localidad\"]=[x.replace('ó',\"o\") for x in cliente[\"Localidad\"]]\n",
    "    cliente[\"Localidad\"]=[x.replace('ú',\"u\") for x in cliente[\"Localidad\"]]\n",
    "\n",
    "    #cliente.isnull().sum()\n",
    "\n",
    "    #merge entre df Localidades y Clientes para traer dato IdLocalidad a Clientes \n",
    "    cliente = pd.merge(cliente,localidad, how=\"left\", on=[\"Provincia\",\"Localidad\"])\n",
    "\n",
    "\n",
    "    #reemplazo Latitud y Longitud sin datos con Latitud y Longitud de tabla Localidades \n",
    "    cliente[\"Longitud_x\"]=cliente.apply(lambda x: x[\"Longitud_y\"] if x[\"Longitud_x\"]==0  else x[\"Longitud_x\"], axis=1)\n",
    "    cliente[\"Latitud_x\"]=cliente.apply(lambda x: x[\"Latitud_y\"] if x[\"Latitud_x\"]==0  else x[\"Latitud_x\"], axis=1)\n",
    "\n",
    "    #cliente.isnull().sum()\n",
    "\n",
    "    #renombro columnas\n",
    "    cliente= cliente.rename(columns= {\"Longitud_x\":\"Longitud\"})\n",
    "    cliente= cliente.rename(columns= {\"Latitud_x\":\"Latitud\"})\n",
    "\n",
    "    #cambio tipo dato Latitud y Longitud\n",
    "    cliente[\"Latitud\"]= cliente.Latitud.astype(float)\n",
    "    cliente[\"Longitud\"]= cliente.Longitud.astype(float)\n",
    "\n",
    "    #elimino columnas que se agregaron en el merge\n",
    "    cliente.drop(['index'], axis = 'columns', inplace=True)\n",
    "\n",
    "\n",
    "    #funcion para encontrar Localidades por similitud - Se recupera IdLocalidad y IdProvincia\n",
    "    def verificarLocalidadClientes(row):\n",
    "        ratiomayor=0\n",
    "        for i in range(0,localidad.shape[0]): \n",
    "\n",
    "                Ratio= fuzz.token_sort_ratio(row[\"Localidad\"].lower(), localidad.Localidad[i].lower())\n",
    "                if Ratio>ratiomayor:\n",
    "                        ratiomayor=Ratio\n",
    "                        miloc=localidad.Localidad[i]\n",
    "                        id=localidad.IdLocalidad[i]\n",
    "                        idprov=localidad.IdProvincia[i]\n",
    "\n",
    "        row[\"Localidad\"]=miloc\n",
    "        row[\"IdLocalidad\"]=id\n",
    "        row[\"IdProvincia\"]=idprov\n",
    "\n",
    "\n",
    "        return row\n",
    "\n",
    "    #cliente.isnull().sum()\n",
    "\n",
    "    #creo DF de cliente con IdLocalidad faltante \n",
    "    clientes_nulos= cliente.loc[cliente['IdLocalidad'].isnull() == True].copy()\n",
    "\n",
    "    #Aplico funcion\n",
    "    clientes_nulos= clientes_nulos.apply(verificarLocalidadClientes,axis=1)\n",
    "\n",
    "    #Borro columnas innecesarias para el merge \n",
    "    clientes_nulos.drop(columns=[\"Latitud_y\",\"Longitud_y\",\"Domicilio\",\"Telefono\",\"Edad\"],inplace=True)\n",
    "\n",
    "    #cliente.isnull().sum()\n",
    "\n",
    "    #merge de Clientes con DF Clientes con IDlocalidad Nulos corregido\n",
    "    cliente = pd.merge(cliente,clientes_nulos, how=\"left\", on=[\"IdCliente\"])\n",
    "\n",
    "    #completo IdLocalidad en tabla cliente original con 0 para prepararlos para el reemplazo\n",
    "    cliente[\"IdLocalidad_x\"]= cliente[\"IdLocalidad_x\"].fillna(0)\n",
    "    cliente[\"IdProvincia_x\"]= cliente[\"IdProvincia_x\"].fillna(0)\n",
    "\n",
    "    #realizo reemplazo de IdLocalidad y IdProvincia traidos con el merge\n",
    "    cliente[\"IdLocalidad_x\"]=cliente.apply(lambda x: x[\"IdLocalidad_y\"] if x[\"IdLocalidad_x\"]==0  else x[\"IdLocalidad_x\"], axis=1)\n",
    "    cliente[\"IdProvincia_x\"]=cliente.apply(lambda x: x[\"IdProvincia_y\"] if x[\"IdProvincia_x\"]==0  else x[\"IdProvincia_x\"], axis=1)\n",
    "\n",
    "    #25 Localidades sin IdLocalidad - se lo completa como sin dato\n",
    "    cliente[\"IdLocalidad_x\"]=cliente[\"IdLocalidad_x\"].fillna(0)\n",
    "\n",
    "    #Elimino columnas innecesarias\n",
    "    cliente.drop(['Latitud_y','Longitud_y','Provincia_y','Nombre_y_Apellido_y','Localidad_y', 'Longitud_y', 'IdLocalidad_y','IdProvincia_y'], axis = 'columns', inplace=True)\n",
    "\n",
    "    #Renombro columnas\n",
    "    cliente= cliente.rename(columns= {\"Provincia_x\":\"Provincia\"})\n",
    "    cliente= cliente.rename(columns= {\"Nombre_y_Apellido_x\":\"Nombre_y_Apellido\"})\n",
    "    cliente= cliente.rename(columns= {\"Localidad_x\":\"Localidad\"})\n",
    "    cliente= cliente.rename(columns= {\"Longitud_x\":\"Longitud\"})\n",
    "    cliente= cliente.rename(columns= {\"Latitud_x\":\"Latitud\"})\n",
    "    cliente= cliente.rename(columns= {\"IdLocalidad_x\":\"IdLocalidad\"})\n",
    "    cliente= cliente.rename(columns= {\"IdProvincia_x\":\"IdProvincia\"})\n",
    "\n",
    "    #cliente.isnull().sum()\n",
    "\n",
    "    #Borro nulos restantes de Latitud\n",
    "    cliente.Latitud.fillna(\"0.0\", inplace=True)\n",
    "    \n",
    "    cliente.to_csv (r'C:/Users/notebook/OneDrive/Escritorio/Henry clase/DS-PI-ProyectoIndividual/Nuevosdataset/ClientesNor.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CargaArchivoClientes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLA PROVEEDORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CargaArchivoProveedores():\n",
    "    #ds_path= pathlib.Path(\"Datasets\")\n",
    "    #print(ds_path)\n",
    "    df_list=[]\n",
    "    #archivo=glob.glob('.csv')\n",
    "    #print(\"Hola\")\n",
    "    for file in glob.glob('Prov*.csv'):\n",
    "        #print(file)\n",
    "        df=pd.read_csv(file,delimiter = ',',encoding = \"Ansi\")\n",
    "        df_list.append(df)\n",
    "    proveedor=pd.concat(df_list)\n",
    "    #proveedor.head()\n",
    "\n",
    "    #Renombro columnas\n",
    "    proveedor = proveedor.rename(columns= {'IDProveedor':'IdProveedor', 'Nombre':'Proveedor','Address':'Direccion', 'City':'Localidad', 'State':'Provincia', 'Country':'Pais', 'departamen':'Departamento'})\n",
    "\n",
    "    #Corrijo letras\n",
    "    proveedor[\"Provincia\"]=[x.replace('á',\"a\") for x in proveedor[\"Provincia\"]]\n",
    "    proveedor[\"Provincia\"]=[x.replace('é',\"e\") for x in proveedor[\"Provincia\"]]\n",
    "    proveedor[\"Provincia\"]=[x.replace('í',\"i\") for x in proveedor[\"Provincia\"]]\n",
    "    proveedor[\"Provincia\"]=[x.replace('ó',\"o\") for x in proveedor[\"Provincia\"]]\n",
    "    proveedor[\"Provincia\"]=[x.replace('ú',\"u\") for x in proveedor[\"Provincia\"]]\n",
    "\n",
    "    proveedor[\"Localidad\"]=[x.replace('á',\"a\") for x in proveedor[\"Localidad\"]]\n",
    "    proveedor[\"Localidad\"]=[x.replace('é',\"e\") for x in proveedor[\"Localidad\"]]\n",
    "    proveedor[\"Localidad\"]=[x.replace('í',\"i\") for x in proveedor[\"Localidad\"]]\n",
    "    proveedor[\"Localidad\"]=[x.replace('ó',\"o\") for x in proveedor[\"Localidad\"]]\n",
    "    proveedor[\"Localidad\"]=[x.replace('ú',\"u\") for x in proveedor[\"Localidad\"]]\n",
    "\n",
    "    #cliente.isna().sum()\n",
    "    #Llena datos vacios\n",
    "    proveedor.Proveedor.fillna('Sin Datos', inplace= True)\n",
    "\n",
    "    #Capitalizo columnas\n",
    "    proveedor['Direccion'] = proveedor['Direccion'].str.title()\n",
    "    proveedor['Localidad'] = proveedor['Localidad'].str.title()\n",
    "    proveedor['Provincia'] = proveedor['Provincia'].str.title()\n",
    "    proveedor['Pais'] = proveedor['Pais'].str.title()\n",
    "    proveedor['Departamento'] = proveedor['Departamento'].str.title()\n",
    "\n",
    "    provincias.reset_index(inplace=True)\n",
    "\n",
    "    #normalizo provincia \n",
    "    lista_provincia=[]\n",
    "    for i in range(provincias.shape[0]):\n",
    "        lista_provincia.append(provincias.loc[i,\"Provincia\"])\n",
    "\n",
    "    #Funcion para encontrar parecidos\n",
    "    def verificarProvinciaProveedores(row):\n",
    "        if(row[\"Provincia\"] not in lista_provincia):\n",
    "                ratiomayor=0\n",
    "                for i in range(0,provincias.shape[0]): \n",
    "                    Ratio= fuzz.token_sort_ratio(row[\"Provincia\"].lower(), provincias.Provincia[i].lower())\n",
    "                    if Ratio>ratiomayor:\n",
    "                            ratiomayor=Ratio\n",
    "                            miloc=provincias.Provincia[i]\n",
    "                row[\"Provincia\"]=miloc\n",
    "        return row\n",
    "\n",
    "    #Corrijo CABA\n",
    "    proveedor['Provincia']=proveedor.apply(lambda x: 'Buenos Aires' if x['Provincia']=='CABA' else x['Provincia'],axis=1)\n",
    "\n",
    "    #Aplico funcion\n",
    "    proveedor=proveedor.apply(verificarProvinciaProveedores, axis=1)\n",
    "\n",
    "    #normalizo ciudad de buenos aires asi porque con la funcion no me la normaliza\n",
    "    ver_loc = list(proveedor['Localidad'].unique())\n",
    "    #for n in ver_loc:\n",
    "        #print(n)\n",
    "\n",
    "    #creamos una lista con las denominaciones más comunes que puede recibir la ciudad de buenos aires\n",
    "    list_BSAS = [\"Ciudad de Buenos Aires\", \"Capital Federal\", \"Cap Fed\", \"CABA\"]\n",
    "    nom_normalizado = [ ]\n",
    "    loc1 = \" \"\n",
    "    loc2 = \" \"\n",
    "    for m in list_BSAS:\n",
    "        loc1 = m\n",
    "        for n in ver_loc:\n",
    "            loc2 = n\n",
    "            Ratio = fuzz.ratio(loc1.lower(),loc2.lower())\n",
    "            Partial_Ratio = fuzz.partial_ratio(loc1.lower(),loc2.lower())\n",
    "            Token_Sort_Ratio = fuzz.token_sort_ratio(loc1, loc2)\n",
    "            Token_Set_Ratio = fuzz.token_set_ratio(loc1, loc2)\n",
    "            if ((Partial_Ratio > 70) and (Token_Set_Ratio > 70)):\n",
    "                nom_normalizado.append(loc2)\n",
    "    print(nom_normalizado)\n",
    "\n",
    "    for n in range (len(nom_normalizado)):\n",
    "        proveedor['Localidad'].loc[(proveedor['Localidad']==str(nom_normalizado[n]))]='Ciudad de Buenos Aires'\n",
    "\n",
    "    #normalizacion de localidad\n",
    "    lista_localidades=[]\n",
    "    for i in range(localidad.shape[0]):\n",
    "        lista_localidades.append(localidad.loc[i,\"Localidad\"])\n",
    "\n",
    "    def verificarLocalidadProveedor(row):\n",
    "        if(row[\"Localidad\"] not in lista_localidades):\n",
    "                ratiomayor=0\n",
    "                for i in range(0,localidad.shape[0]): \n",
    "                    Ratio= fuzz.token_sort_ratio(row[\"Localidad\"].lower(), localidad.Localidad[i].lower())\n",
    "                    if Ratio>ratiomayor:\n",
    "                            ratiomayor=Ratio\n",
    "                            miloc=localidad.Localidad[i]\n",
    "                row[\"Localidad\"]=miloc\n",
    "        return row\n",
    "\n",
    "    proveedor=proveedor.apply(verificarLocalidadProveedor, axis=1)\n",
    "\n",
    "    #traigo idlocalidad con el merge\n",
    "    proveedor = pd.merge(proveedor,localidad, how=\"left\", on=[\"Localidad\",\"Provincia\"])\n",
    "    proveedor.drop(['Pais','Departamento','index','Latitud','Longitud','Localidad','Provincia'], axis = 'columns', inplace=True)\n",
    "\n",
    "    #proveedor.isnull().sum()\n",
    "\n",
    "    proveedor.to_csv (r'C:/Users/notebook/OneDrive/Escritorio/Henry clase/DS-PI-ProyectoIndividual/Nuevosdataset/PreveedoresNor.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "CargaArchivoProveedores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLA SUCURSAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CargaArchivoSucursal():\n",
    "    #ds_path= pathlib.Path(\"Datasets\")\n",
    "    #print(ds_path)\n",
    "    df_list=[]\n",
    "    #archivo=glob.glob('.csv')\n",
    "    #print(\"Hola\")\n",
    "    for file in glob.glob('Sucursa*.csv'):\n",
    "        print(file)\n",
    "        df=pd.read_csv(file,delimiter = ';',encoding = \"utf-8\")\n",
    "        df_list.append(df)\n",
    "    sucursal=pd.concat(df_list)\n",
    "    #sucursal.head()\n",
    "\n",
    "    #Renombro columnas\n",
    "    sucursal = sucursal.rename(columns= {'ID':'IdSucursal'})\n",
    "\n",
    "    #Corrijo letras\n",
    "    sucursal[\"Provincia\"]=[x.replace('á',\"a\") for x in sucursal[\"Provincia\"]]\n",
    "    sucursal[\"Provincia\"]=[x.replace('é',\"e\") for x in sucursal[\"Provincia\"]]\n",
    "    sucursal[\"Provincia\"]=[x.replace('í',\"i\") for x in sucursal[\"Provincia\"]]\n",
    "    sucursal[\"Provincia\"]=[x.replace('ó',\"o\") for x in sucursal[\"Provincia\"]]\n",
    "    sucursal[\"Provincia\"]=[x.replace('ú',\"u\") for x in sucursal[\"Provincia\"]]\n",
    "\n",
    "    sucursal[\"Localidad\"]=[x.replace('á',\"a\") for x in sucursal[\"Localidad\"]]\n",
    "    sucursal[\"Localidad\"]=[x.replace('é',\"e\") for x in sucursal[\"Localidad\"]]\n",
    "    sucursal[\"Localidad\"]=[x.replace('í',\"i\") for x in sucursal[\"Localidad\"]]\n",
    "    sucursal[\"Localidad\"]=[x.replace('ó',\"o\") for x in sucursal[\"Localidad\"]]\n",
    "    sucursal[\"Localidad\"]=[x.replace('ú',\"u\") for x in sucursal[\"Localidad\"]]\n",
    "\n",
    "    #modificamos el tipo de dato de la columna longitud\n",
    "    sucursal[\"Longitud\"] = sucursal[\"Longitud\"].str.replace(\",\", \".\").astype(float)\n",
    "    sucursal[\"Latitud\"] = sucursal[\"Latitud\"].str.replace(\",\", \".\").astype(float)\n",
    "\n",
    "    #sucursal.isnull().sum()\n",
    "\n",
    "    #normalizacion de provincia\n",
    "    lista_provincia=[]\n",
    "    for i in range(provincias.shape[0]):\n",
    "        lista_provincia.append(provincias.loc[i,\"Provincia\"])\n",
    "\n",
    "    #Funcion para encontrar parecios\n",
    "    def verificarProvincia(row):\n",
    "        if(row[\"Provincia\"] not in lista_provincia):\n",
    "                ratiomayor=0\n",
    "                for i in range(0,provincias.shape[0]): \n",
    "                    Ratio= fuzz.token_sort_ratio(row[\"Provincia\"].lower(), provincias.Provincia[i].lower())\n",
    "                    if Ratio>ratiomayor:\n",
    "                            ratiomayor=Ratio\n",
    "                            miprov=provincias.Provincia[i]\n",
    "                row[\"Provincia\"]=miprov\n",
    "        return row\n",
    "\n",
    "    #Corrijo CABA \n",
    "    sucursal['Provincia']=sucursal.apply(lambda x: 'Buenos Aires' if x['Provincia']=='CABA' else x['Provincia'],axis=1)\n",
    "\n",
    "    #Aplico funcion\n",
    "    sucursal=sucursal.apply(verificarProvincia, axis=1)\n",
    "\n",
    "    #normalizo ciudad de buenos aires asi porque con la funcion no me la normaliza\n",
    "    ver_loc = list(sucursal['Localidad'].unique())\n",
    "    #for n in ver_loc:\n",
    "        #print(n)\n",
    "\n",
    "    # Creamos una lista con las denominaciones más comunes que puede recibir la ciudad de buenos aires\n",
    "    list_BSAS = [\"Ciudad de Buenos Aires\", \"Capital Federal\", \"Cap Fed\", \"CABA\"]\n",
    "    nom_normalizado = [ ]\n",
    "    loc1 = \" \"\n",
    "    loc2 = \" \"\n",
    "    for m in list_BSAS:\n",
    "        loc1 = m\n",
    "        for n in ver_loc:\n",
    "            loc2 = n\n",
    "            Ratio = fuzz.ratio(loc1.lower(),loc2.lower())\n",
    "            Partial_Ratio = fuzz.partial_ratio(loc1.lower(),loc2.lower())\n",
    "            Token_Sort_Ratio = fuzz.token_sort_ratio(loc1, loc2)\n",
    "            Token_Set_Ratio = fuzz.token_set_ratio(loc1, loc2)\n",
    "            #print(f\"* {loc1} vs {loc2}\")\n",
    "            #print(Ratio)\n",
    "            #print(Partial_Ratio)\n",
    "            #print(Token_Sort_Ratio)\n",
    "            #print(Token_Set_Ratio, \"\\n\")\n",
    "            if ((Partial_Ratio > 70) and (Token_Set_Ratio > 70)):\n",
    "                nom_normalizado.append(loc2)\n",
    "    print(nom_normalizado)\n",
    "\n",
    "    for n in range (len(nom_normalizado)):\n",
    "        sucursal['Localidad'].loc[(sucursal['Localidad']==str(nom_normalizado[n]))]='Ciudad de Buenos Aires'\n",
    "\n",
    "    #normalizacion de localidad\n",
    "    lista_localidades=[]\n",
    "    for i in range(localidad.shape[0]):\n",
    "        lista_localidades.append(localidad.loc[i,\"Localidad\"])\n",
    "\n",
    "    def verificarLocalidad(row):\n",
    "        if(row[\"Localidad\"] not in lista_localidades):\n",
    "                ratiomayor=0\n",
    "                for i in range(0,localidad.shape[0]): \n",
    "                    Ratio= fuzz.token_sort_ratio(row[\"Localidad\"].lower(), localidad.Localidad[i].lower())\n",
    "                    if Ratio>ratiomayor:\n",
    "                            ratiomayor=Ratio\n",
    "                            miloc=localidad.Localidad[i]\n",
    "                row[\"Localidad\"]=miloc\n",
    "        return row\n",
    "\n",
    "    sucursal=sucursal.apply(verificarLocalidad, axis=1)\n",
    "\n",
    "    #traigo idlocalidad con el merge\n",
    "    sucursal = pd.merge(sucursal,localidad, how=\"left\", on=[\"Localidad\",\"Provincia\"])\n",
    "\n",
    "    sucursal.drop(['Latitud_y','Longitud_y', 'Localidad', 'Provincia', 'index', 'Latitud_x', 'Longitud_x',], axis = 'columns', inplace=True)\n",
    "\n",
    "    #localidad.isnull().sum()\n",
    "    sucursal.to_csv (r'C:/Users/notebook/OneDrive/Escritorio/Henry clase/DS-PI-ProyectoIndividual/Nuevosdataset/SucursalesNor.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucursales.csv\n",
      "['Ciudad de Buenos Aires', 'Cdad de Buenos Aires', 'Capital', 'Capital Federal', 'Cap.   Federal', 'CapFed', 'Cap. Fed.', 'CABA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\notebook\\AppData\\Local\\Temp\\ipykernel_6672\\37095291.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sucursal['Localidad'].loc[(sucursal['Localidad']==str(nom_normalizado[n]))]='Ciudad de Buenos Aires'\n"
     ]
    }
   ],
   "source": [
    "CargaArchivoSucursal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b553e1a3709e32c1fb0467a3664802744a4b07a98d83f2e16b766e49821e4ae3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
